\section{Capitolo 1 - Introduzione}

\subsection{Tipi di collegamento}
Ci sono due tipi di collegamento:
\begin{itemize}
\item \textbf{Poin-to-Point} - la comunicazione avviene tra due macchine tramite dei pacchetti.
\item \textbf{Broadcast} - esiste un canale condiviso da tutte le macchine;
una volta inviato un pacchetto viene ricevuto da tutti e viene processato solo dalla macchina che ha l'indirizzo indicato nel pacchetto;
è possibile anche mandare un pacchetto a tutte le macchine della rete con un codice speciale nel campo indirizzo del pacchetto.
\end{itemize}

\subsection{Classificazione delle reti}
Classificazione delle reti in base alla distanza dei processori:
\begin{itemize}
\item PAN - Personal Area Network
\item LAN - Local (Stanza/Edificio)
\item MAN - Metropolitan (Città)
\item WAN - Wide (Nazione/Continente)
\item Internet (Pianeta)
\end{itemize}

\subsection{Architettura delle reti}
L'architettura delle reti è composta da livelli e protocolli.
Una rete è organizzata come una pila di livelli i quali offrono servizi ai livelli superiori, senza dare dettagli implementativi.

Un livello di un computer comunica con lo stesso livello di un altro computer.
Le entità su uno stesso livello sono detti peer (pari).
Tuttavia i dati non passano direttamente da un livello $n_A$ ad un livello $n_B$, ma dovranno essere passati ai sottolivelli di A per poi risalire i livelli di B.

Le regole e le convenzioni per la comunicazione tra livelli pari sono note come \textbf{protocolli} di livello.
Un protocollo indica come deve avvenire la comunicazione tra le parti (es: il formato e significato dei pacchetti).

Infine, tra i livelli sono presenti le \textbf{interfacce}, che definiscono i \textit{servizi} (cioè un insieme di primitive/operazioni) che il livello inferiore mette a disposizione del soprastante.

In una rete strutturata bene è possibile sostituire l'implementazione di un livello perché quella nuova dovrà solo rendere disponibile al livello soprastante gli stessi servizi della vecchia.

\subsubsection{Progettare una rete}

I punti chiave da tenere in considerazione quando si progetta una rete sono:
\begin{itemize}
\item Affidabilità
\begin{itemize}
\item individuare gli errori e, se possibile, correggerli;
\item trovare un percorso valido tra sorgente e destinatario (routing/instradamento);
\end{itemize}
\item Evoluzione della rete
\item Allocazione delle risorse
\begin{itemize}
\item gestire una banda condivisa;
\item impedire che una sorgente veloce inondi un ricevitore lento (flow control) per evitare una congestione;
\end{itemize}
\item Sicurezza della rete
\end{itemize}

\subsubsection{Tipi di servizi offerti da un livello}
Un livello può offrire un servizio orientato alla connessione o senza connessione.

Il primo richiede di stabilire una connessione, usarla e rilasciarla una volta terminato. 
In questo servizio le informazioni inviate mantengono l'ordine di partenza.

Nel servizio senza connessione ogni pacchetto viene mandato al destinatario indipendentemente dai messaggi successivi, quindi non c'è sicurezza che l'ordine sia mantenuto. 

Inoltre c'è una questione legata all'affidabilità. 
Un servizio è considerato affidabile se riceve sempre tutti i pacchetti e di solito avviene tramite una conferma di ricezione. 
La conferma tuttavia rallenta le prestazioni del servizio, quindi è necessario valutare nei singoli casi se ne vale la pena: 
ad esempio in un servizio di streaming è più importante la velocità per un servizio più fluido piuttosto che l'affidabilità per una qualità migliore dell'audio/video.

Un esempio di primitive di un servizio orientato alla connessione sono: Listen, Connect, Accept, Receive, Send, Disconnect.

\subsection{Modelli di reti}
Esistono due architetture di rete principali utilizzate come modello: OSI e TCP/IP. \\
Il primo utilizza 7 livelli:
\begin{enumerate}
\item fisico
\item data link
\item rete
\item trasporto
\item sessione
\item presentazione
\item applicazione
\end{enumerate}
Il secondo utilizza 4 livelli:
\begin{enumerate}
\item link - livello  di accesso alla rete per spedire i pacchetti IP.
\item internet - livello che gestisce l'indirizzamento dei nodi e l'instradamento, assegnando ad ogni nodo un indirizzo IP e indicando il percorso migliore verso il destinatario.
\item trasporto - livello che gestisce la comunicazione, tramite protocollo TCP o UDP.
\item applicazione - livello più vicino all'utente che gestisce le sessioni e la presentazione; alcuni protocolli di questo livello sono HTTP e DNS.
\end{enumerate}
Il libro e il corso utilizza un modello ibrido a 5 livelli:
\begin{enumerate}
\item fisico - indica come vengono trasmessi i bits tramite segnali elettrici o simili.
\item link - indica come mandare i messaggi ai computer (es. Ethernet, 802.11).
\item rete - indica come combinare link multipli per spedire pacchetti tra computer distanti
\item trasporto - gestisce la comunicazione, tramite protocollo TCP o UDP.
\item applicazione - programmi che usano il network
\end{enumerate}

\newpage
\section{Capitolo 2 - Strato fisico}

L'obiettivo dello strato fisico è quello di trasportare i bits da una macchina ad un'altra.
Per farlo si possono usare diversi mezzi fisici con proprie caratteristiche.
I mezzi di trasmissione possono essere guidati (es: cavi) o non guidati (wireless, satelliti).

Le informazioni possono essere trasmesse su cavi sfruttando proprietà come voltaggio o corrente. 
Usando questi valori, si può modellare il comportamento del segnale e analizzarlo matematicamente.

\subsection{Serie di Fourier e Banda passante}

Fourier afferma che una funzione periodica con periodo T può essere costruita come la somma di un numero n di seni e coseni.
Da ciò deriva la serie di Fourier, una formula che permette di ricostruire la suddetta funzione periodica. 
Nel contesto delle reti, un segnale che ha durata finita può essere immaginato come un pattern che viene ripetuto con l'intervallo T e 2T identico all'intervallo 0 a T.
In questo modo, conoscendo periodo e ampiezza è possibile ricostruire la funzione del segnale, permettendo un analisi e modellazione più facile del segnale.
Il problema è che i mezzi di trasmissione perdono parte della potenza del segnale, generando una distorsione.
Un cavo riesce a trasmettere frequenze senza attenuazione in un intervallo che va da 0 a $f_c$ (frequenza di cutoff).
Questo intervallo è detto Banda passante (\textit{bandwidth}) e dipende da diversi fattori del mezzo di trasmissione (materiali, lunghezza e spessore di un cavo, ecc).
Le frequenze che vanno oltre vengono attenuate.
La frequenza di cutoff non è ben definita, quindi di solito si pone l'intervallo da 0 fino alla frequenza dove la potenza del segnale è dimezzata.
Questi sono detti segnali baseband.
A volte vengono utilizzati dei filtri che possono modificare la banda passante, per esempio alzando l'intervallo da un valore maggiore di zero: è il caso delle trasmissioni wireless.
Questi sono segnali passband.

\subsection{Mezzi di trasmissione guidati}

\subsubsection{Mezzi magnetici}
I mezzi magnetici sono un comune mezzo di trasporto per dati (cd, dcd, hdd) che in alcuni casi può risultare più conveniente se considerato un rapporto dimensioneDati/tempoTrasferimento.
Per esempio può essere più comodo trasportare un camion di hard disk piuttosto che spedire lo stesso quantitativo di dati tramite la rete. 
Anche se le connessioni stanno diventando sempre più veloci, in alcuni casi i mezzi magnetici possono rimanere la miglior soluzione (sempre da considerare il contesto).

\subsubsection{Il doppino}
Il doppino è un cavo composto da due conduttori in rame isolati di 1mm, attorcigliati in modo elicoidale (simile al DNA).
Questa forma permette di eliminare i campi elettromagnetici che si verrebbero a formare se fossero paralleli.
Un segnale è tramesso come differenza di voltaggio tra i due cavi, in modo da evitare i disturbi da rumori esterni(?).
L'uso più comune è per il telefono e l'accesso ad internet con l'ADSL. 
Il doppino può estendersi per chilometri, ma dopo certe distanze è necessario un ripetitore altrimenti il segnale diventa troppo attenuato.
Il prezzo del doppino è ridotto e ha una velocità di trasmissione moderata.
Si possono usare per segnali sia analogici che digitali e la larghezza di banda dipende dallo spessore del cavo e dalla distanza percorsa, tuttavia è limitata.

Esistono diversi tipi di cavi che utilizzano il doppino, come Cat 3 e Cat 5.
Questi consistono in due cavi isolati attorcigliati tra loro, raggruppati con altre coppie (4 totali), ricoperti da una protezione in plastica.
La differenza tra le due tipologie sta nel numero di spire per metro: maggior numero di spire significa una maggior qualità del segnale su lunghe distanze.
Esistono categorie superiori come Cat 6 e 7 che supportano segnali con una maggiore larghezza di banda (fino a 500 MHz).

\subsubsection{Il cavo coassiale}
Il cavo coassiale è un mezzo trasmissivo che permette una maggior larghezza di banda (fino a qualche GHz) rispetto al doppino grazie alla migliore schermatura,
permettendo di viaggiare a maggiori velocità a lunghe distanze.
In particolare, il cavo è composto da un nucleo conduttore in rame, ricoperto da un materiale isolante,
il quale a sua volta è ricoperto da un conduttore cilindrico intrecciato (tipo una rete), protetto da una guaina in plastica.
Esistono due tipi di cavi coassiali, usati in base al tipo di segnale.
Il 50$\Omega$ viene usato per i segnali digitali, mentre il 75$\Omega$ per i segnali analogici e per la televisione.
Questo cavo veniva usato anche nel campo della telefonia, ma ormai sta venendo rimpiazzato dalla fibra ottica. Viene ancora usato per la tv via cavo e per le MAN.

\subsubsection{Fibra ottica}
Un sistema di trasmissione ottico si basa su una fonte luminosa, un mezzo di trasmissione e un ricevitore.
La presenza di luce indica un 1 mentre l'assenza uno 0.
Nel caso della fibra ottica, si utilizza una sottilissima fibra di vetro come nucleo, attraverso la quale viaggia la luce. 
Alle estremità un ricevitore che "legge" i segnali luminosi e li traduce in segnali elettrici.
La buona riuscita della trasmissione del raggio luminoso sta negli indici di rifrazione dei componenti della fibra ottica. 
Grazie ad essi il raggio luminoso rimane nella fibra e continua il suo percorso fino a destinazione.
Infatti il core è ricoperto da un rivestimento di vetro (cladding) che ha un indice di rifrazione più basso, e a sua volta è ricoperto da uno strato protettivo in plastica.
Di solito le fibre sono raggruppati in fasci, a loro volta protetti da una guaina esterna.

In base allo spessore del nucleo, la fibra cambia il proprio nome.
Se un raggio al suo interno è propagato grazie ai rimbalzi della rifrazione, si dice multimodale (50 microns).
Se la fibra è abbastanza sottile da far procedere il raggio quasi in linea retta, si dice monomodale (8-10 microns).
Quest'ultima è più costosa ma più efficiente sulle lunghe distanze.

Ci sono tre modi per connettere la fibra ottica:
\begin{itemize}
\item collegamento della parte finale ad un connettore in apposite prese, con una perdita del 10-20\% del segnale luminoso ma una facile riconfigurazione del sistema
\item attaccate meccanicamente, cercando di allinearle al meglio, con una perdita del 10\% del segnale
\item fusione delle due parti, generando una piccola attenuazione
\end{itemize}

Le fonti luminose possono essere LED (basso data rate, multimodale, low cost) o laser semiconduttori (alto data rate, sia mono che multimodale, costoso).

Il ricevitore che converte il segnale luminoso in elettrico ha un limite di data rate di 100 Gbps.
Inoltre l'interferenza termica può risultare un problema, quindi conviene utilizzare raggi luminosi abbastanza potenti da essere rilevati.

La fibra ottica è una tecnologia relativamente recente, di conseguenza non tutti gli addetti hanno le conoscenze necessarie per installarla od utilizzarla correttamente;
può anche danneggiarsi se si piega troppo. 
Inoltre la trasmissione è monodirezionale, quindi sono richiesti due cavi per andata e ritorno, e le interfacce sono più costose.

Tuttavia ha una maggior ampiezza di banda, richiede meno ripetitori (uno ogni 50km contro uno ogni 5 di quelli in rame), il che porta ad un risparmio,
è più sottile, richiedendo quindi meno spazio, è più sicura perché non è possibile intercettare la luce ed infine è più adatta ai luoghi inospitali, in quanto subisce meno interferenze.

\subsection{Mezzi wireless}

\subsubsection{Spettro elettromagnetico}
Lo spostamento degli elettroni crea onde elettromagnetiche:
il numero di oscillazioni al secondo di un'onda è detta frequenza (misurata in Hz),
mentre la distanza tra due massimi è detta lunghezza d'onda (indicata da lambda).
Un'antenna collegata ad un circuito elettrico riesce a trasmettere onde elettromagnetiche.
Nel vuoto le onde viaggiano tutte alla velocità della luce, nei cavi la velocità scende a 2/3 di quella della luce.

Lo spettro elettromagnetico è composto da diversi tipi di onde in base alla frequenza:
radio, microonde, infrarosso, luce visibile, ultravioletti, raggi x e raggi gamma.
Queste si possono usare per trasmettere segnali; le ultime tre sarebbero le migliori ma non vengono usate per la difficoltà nel generarle e sono dannose per gli esseri viventi.

Di solito si usa una banda di frequenza ristretta per avere una migliore ricezione, ma in alcuni casi si utilizza la banda larga con due varianti:
\begin{itemize}
\item spettro distribuito a frequenza variabile (frequency hopping), dove il trasmettitore salta da una frequenza all'altra centinaia di volte al secondo (adottato dal 802.11)
\item spettro distribuito a sequenza diretta (direct sequence)
\end{itemize}

\subsubsection{Trasmissioni radio}
Le onde radio sono onde a bassa frequenza, facili da generare, che possono viaggiare per lunghe distanze e attraversano facilmente gli edifici. 
Queste onde sono omnidirezionali, cioè si espandono in tutte le direzioni, quindi non necessitano che il trasmettitore e il ricevitore siano allineati.
Le onde radio sono soggette a interferenze da motori e da altri dispositivi elettrici.

A bande basse (VLF, LF, MF), le onde radio seguono il terreno e si possono ricevere fino a 1000km.
Le stazioni radio AM usamo le MF che permettono di attraversare facilmente gli edifici.
Le bande alte (HF, VHF) sfruttano i rimbalzi contro la ionosfera per ottenere trasmissioni a distanze maggiori.

\subsubsection{Trasmissioni a microonde}
Sopra i 100MHz le onde viaggiano quasi in linea retta, rendendo possibile la messa a fuoco.
Si concentra l'energia in un unico raggio trasmesso tramite un'antenna parabolica, tuttavia è richiesto che sia allineata con l'antenna ricevente.
Se da un lato è una limitazione non da poco, dall'altro permette di trasmettere più raggi in parallelo senza interferenze.
Quando le antenne sono lontane, entra in gioco la curvatura della terra e sono quindi necessari dei ripetitori.
Più sono in alto le antenne, maggiore è la distanza raggiungibile.

Esiste un problema con le microonde. Anche se sono dirette, possono divergere e rifrangere sugli strati più bassi dell'atmosfera,
arrivando fuorifase con le dirette, il che può annullare il segnale.
L'effetto è detto multipath fading e può essere determinato dalle condizioni climatiche e dalla frequenza.
La richiesta di spettro ha portato ad utilizzare frequenze più alte, ma queste hanno il problema di venire assorbite dall'acqua. 
In entrambi i casi, la soluzione è interrompere la trasmissione in caso di pioggia e utilizzare altri mezzi.

Nonostante questi problemi, le microonde sono molto utilizzate per le comunicazioni telefoniche a lunga distanza, nella telefonia cellulare e nella televisione.
Rispetto a mezzi come la fibra, basta una semplice antenna e non è richiesto alcun diritto di passaggio. 
\`E inoltre più economica da installare.
Esiste però un altro problema, ovvero il bisogno di più frequenze dello spettro.
Sono stati stipulati degli accordi per gestire le frequenze utilizzabili (Come? Concorso di bellezza, lotteria, non assegnandole). 

\subsubsection{Infrarossi}
Queste onde sono utilizzate per la comunicazione a cortoraggio (esempio i telecomandi).
\`E un sistema economico ma che non attraversa gli ostacoli solidi.
Tuttavia questa limitazione torna comoda in determinate situazioni perché non riuscendo ad attraversare i muri non crea interferenze.

\subsubsection{Trasmissioni a onde luminose}
La trasmissione utilizzando laser è unidirezionale e richiede quindi due laser e due rilevatori.
L'ampiezza di banda offerta è elevata, a costo ridotto e di facile installazione.
Tuttavia puntare il laser richiede molta precisione e non posso attraversare pioggia e nebbia.
Anche le giornate serene possono creare problemi in quanto il caldo può creare correnti di convezione che deviano il raggio.

\subsection{Satelliti}

Un satellite è composto da tanti transponder che ascoltano una diversa porzione dello spettro elettromagnetico.
Quando riceve un segnale in arrivo, il relativo transponder lo amplifica e lo ritrasmette con frequenza diversa per evitare interferenze.
Esistono tre tipi di satelliti in base alla loro posizione: GEO, MEO, LEO.\\
Vai a §\ref{satelliti} per il confronto delle tre tipologie.

\subsection{Rete telefonica pubblica commutata}
Il PSTN, ovvero Public Switched Telephone Network, rete telefonica pubblica commutata, è uno dei sistemi di comunicazione esistenti. 

Il sistema telefonico è strutturato secondo una gerarchia multilivello ad alta ridondanza.
Da ogni telefono partono due cavi di rame collegati alla centrale locale (la più vicina). 
Se la chiamata avviene tra due utenti collegati alla stessa centrale, questa crea una connessione elettrica tra i due e rimane aperta fino al termine della chiamata.
Se invece i due telefoni sono collegati a due centrali diverse, le centrali locali si collegano con una centrale interurbana che crea la connessione. 
Se tuttavia non si collegano alla stessa centrale interurbana, cercano di collegarsi a stazioni intermedie di livello superiore.

I collegamenti locali utilizzano il doppino con segnali analogici, mentre le linee utilizzano le fibre ottiche digitali per collegare le centrali di commutazione.

\subsubsection{Collegamenti locali}
Il collegamento locale, spesso chiamato anche "ultimo miglio", utilizza tutt'ora la trasmissione analogica.
Innanzitutto, per spedire dati digitali devono essere convertiti in analogici dal modem. 
Una volta giunta la centrale, i dati vengono riconvertiti in digitale.
Il ricevente farà la conversione inversa.
Il segnale analogico viene trasmesso tramite la variazione di tensione, quindi il segnale ricevuto non sarà mai identico, il che può determinare errori.
I problemi sono 3:
\begin{itemize}
    \item attenuazione, rappresenta la perdita di energia causata dalla propagazione del segnale e dipende dalla frequenza
    \item distorsione, il segnale si modifica a causa della differenza di velocità con cui si propagano i componenti di Fourier attraverso il cavo
    \item rumore, cioè l'energia indesiderata generata da sorgenti esterne al trasmettitore
\end{itemize}

\paragraph{Modem}
Dato che i problemi descritti sopra sono molto legati alla frequenza, conviene che venga utilizzato un intervallo ridotto.
I segnali digitali tuttavia usano un ampio spettro di frequenza e sono quindi molto soggetti ad attenuazione e distorsione.
Si utilizza come soluzione la trasmissione AC, introducendo un tono continuo, detto portante d'onda sinusoidale, nell'intervallo 1000-2000 Hz.
Modulando ampiezza, frequenza e fase si possono trasmettere le informazioni.
Nella modulazione d'ampiezza di usano due ampiezze diverse per indicare 1 o 0.
Nella modulazione di frequenza si utilizzano due o più toni.
Nella modulazione di fase l'onda portante è spostata di 0 o 180 a intervalli uniformi.

Il modem accetta i bit in ingresso e produce la portante utilizzando i metodi di modulazione (e viceversa).

Il numero di campioni al secondo è misurato in baud. 
Durante ogni baud viene trasmesso un simbolo, quindi una linea a \textit{n} baud trasmette \textit{n} simboli al secondo.
Questa misura è detta Baudrate, che è diverso dal Bitrate.
Il Bitrate indica quanti bit al secondo (bps) vengono trasmessi, mentre il Baudrate indica il numero di simboli trasmessi.
Quindi la differenza tra i due è determinato da quanti bit rappresenta un simbolo ed è determinato dalla tecnica di modulazione utilizzata. 
Se viene utilizzato il voltaggio 0V=0 e 1V=1, allora Bitrate e Baudrate equivalgono, ma se ogni simbolo è composto da 2 o più bit, il Bitrate sarà conseguentemente maggiore.
Quando ci sono 4 possibili cambi di fase e quindi un simbolo descrive 2 bit, la tecnica di modulazione è detta QPSK (Quadrature Phase Shift Keying).

Un'altra tecnica di modulazione è la QAM-16, la quale utilizza 4 bit per simbolo (4 ampiezze e 4 fasi). Se vengono utilizzati 5 bit è detta QAM-32, 6 bit QAM-64.

I diagrammi di costellazione indicano le combinazioni valide di ampiezza e fase. 
Un modem può comunicare solo con altri model che usano la stessa costellazione, ma sono molto soggette ad errori in quanto basta un'alterazione dell'ampiezza o della fase per perdere informazioni.
Per risolvere questo problema sono stati introdotti bit di parità per implementare codice di correzione di errori.
Questi schemi sono detti TCM (Trellis Coded Modulation). Lo standard V32 usa 4 bit di dati e uno di parità.
Il V32 bis usa 6 bit di dati e 1 di parità. Ci sono anche versioni superiori.

I modem moderni permettono la trasmissione bidirezionale utilizzando frequenze diverse.
Una connessione che permette di viaggiare \textbf{contemporaneamente} in entrambi i sensi è detta full duplex, mentre half duplex se solo una direzione è supportata.
Se permette di viaggiare solo in una direzione è detta simplex (es: fibra ottica).

\paragraph{DSL, Digital Subscriber Line}
I collegamenti locali che usano il modem si collegano al commutatore con un filtro che limita la frequenza,
mentre chi utilizza le tecnologie DLS si connettono ad un diverso commutatore che non presenta il filtro.
Quindi il limite non è più il filtro, bensì le proprietà fisiche del mezzo.

Il primo ADSL divideva lo spettro tra:
\begin{itemize}
    \item servizio telefonico
    \item upstream
    \item downstream
\end{itemize}
La tecnica di divisione è detta multiplexing a divisione di frequenza.
Il metodo alternativo è il DMT (Discrete MultiTone), che divide in 256 canali lo spettro.
Il canale 0 è per la voce, i canali 1-5 non usati, uno per upstream e uno per downstream, gli altri a disposizione dei dati dell'utente.
Quelli liberi per i dati di solito vengono distribuiti secondo il provider tra up e down.

\subsection{Linee e multiplexing}
Le aziende telefoniche hanno organizzato il sistema per utilizzare un unico collegamento fisico sia per la banda larga che per quella stretta.
Per fare ciò viene utilizzato il multiplexing, che si distingue in due tipologie:
\begin{itemize}
    \item FDM: Frequency division multiplexing, dove lo spettro è diviso in bande di frequenza e ogni utente ha a disposizione solo alcune parti
    \item TDM: Time division multiplexing, dove la banda viene scambiata per intero tra gli utenti per breve tempo
\end{itemize}

\subsubsection{Multiplexing a divisione di frequenza}
[...]

\subsubsection{Multiplexing a divisione di lunghezza d'onda}
Questo multiplexing è utilizzato per i canali in fibra ottica.
[...]

\subsubsection{Multiplexing a divisione di tempo}
[...]

\subsection{Commutazione (\textit{Switching})}

\subsubsection{Commutazione di circuito}
La commutazione di circuito è la tecnica che crea il percorso fisico tra i due telefoni comunicanti. 
Quando una chiamata arriva ad una centrale di commutazione, viene stabilita una connessione fisica tra la linea entrante e quella d'uscita della centrale.
Questo tipo richiede di configurare il percorso \textbf{prima} di iniziare a trasmettere i dati.

\subsubsection{Commutazione di messaggio}
Questa commutazione non richiede un percorso fisico prestabilito. 
Quando viene inviato un blocco di dati, questo viene inviato alla prima centrale e vengono instradate un passo alla volta. 
Ad ogni passo viene controllato che il blocco ricevuto non contenga errori e poi ritrasmesso.
Una rete che utilizza questa tecnica è detta \textit{store and forward}.
Il blocco può essere di qualsiasi dimensione, richiedendo dischi capaci di memorizzarli temporaneamente, e possono occupare per un tempo considerevole una linea.

\subsubsection{Commutazione di pacchetto}
Per risolvere i problemi della commutazione di messaggio, si utilizza quella di pacchetto che impone una dimensione massima del pacchetto e si assicura che non occupino per troppo tempo una linea.
Un altro vantaggio è che un pacchetto che fa parte di un messaggio può essere mandato prima che finisca di arrivare il successivo.
Come per quella di messaggio, non è richiesta la preparazione fisica del percorso prima della trasmissione.
I pacchetti possono seguire strade diverse e non arrivare in ordine.

La commutazione di circuito riserva l'ampiezza di banda per tutto il percorso, mentre quella di pacchetto no.
Quindi la prima soluzione garantisce il servizio, con spreco di risorse, mentre il secondo no.
Anche quella di pacchetto usa la tecnica \textit{store and forward}. 
Un'altra differenza è che la commutazione di circuito dà libertà di velocità, formato e framing, mentre in quella di pacchetto sono dipendenti dall'onda portante.
Ultima differenza riguarda l'addebito: per il circuito dipende da tempo e distanza, per il pacchetto dipende dal volume dei dati.

\subsection{Sistema telefonico mobile}

\subsubsection{Prima generazione - voce analogica}
Prima versione: sistema telefonico per auto, che usava un pulsante per attivare il trasmettitore e disattivare il ricevitore. Quindi una sola direzione alla volta.\\
Seconda versione: IMTS, usa due frequenze, una per trasmettere e una per ricevere. La frequenza disponibile era limitata, quindi richiedeva del tempo per avere la linea libera.

AMPS è il sistema telefonico mobile avanzato da cui deriva la versione digitale D-AMPS.
Un'area geografica è divisa in celle di 10-20Km, ognuna delle quali utilizza frequenze diverse da quelle vicine.
Il vantaggio di questa organizzazione è che celle vicine (ma non quelle adiacenti) possono usare le stesse frequenze, a differenza del IMTS che si estendeva per 100Km.
Si ottiene quindi una maggiore capacità del sistema e riducendo la grandezza delle celle si riesce ad aumentare ulteriormente la capacità, richiedendo anche meno potenza per i trasmettitori.
Il principale problema è trovare una posizione elevata per le antenne base, che sono gestite dalla stazione base, di solito al centro di ogni cella.
La stazione è composta da un computer e un trasmettitore/ricevitore connesso all'antenna.
Le stazioni sono collegate a dei commutatori per il mobile, cioè il MTSO (Mobile Telephone Switching Office).
Se la rete è piccola si collegano allo stesso commutatore, altrimenti si crea una gerarchia a livelli simile alla rete telefonica cablata.
Viene utilizzata la commutazione di pacchetto.

Quando un telefono abbandona una cella perché il segnale di sta affievolendo, la stazione base verifica la potenza del segnale delle celle adiacenti e trasferisce la gestione del dispositivo.
Il telefono è informato del cambiamento e se era in corso una chiamata viene forzato a passare su un altro canale. 
Questo processo è detto \textbf{handoff}. Esistono due tipi:
\begin{itemize}
    \item soft handoff, dove la nuova stazione acquisisce la gestione del telefono prima di interrompere il segnale;
    non c'è perdita di continuità ma il telefono deve essere capace di gestire le due frequenze contemporaneamente (solo la terza generazione di telefoni riesce)
    \item hard handoff, la vecchia stazione rilascia il telefono prima che la nuova lo acquisisca;
    è un processo abbastanza veloce, ma la chiamata può venire interrotta se la stazione non è in grado di gestire il nuovo dispositivo
\end{itemize}
AMPS usa 832 canali duplex composti da una coppia di simplex. 
AMPS usa FDM (Frequency Division Multiplexing) per separare i canali.
I canali sono divisi in 4 categorie:
\begin{itemize}
    \item controllo, dalla base al telefono, per gestire il sistema
    \item paging, dalla base al telefono, per notificare la chiamata all'utente
    \item accesso, bidirezionale, per impostare chiamata e canale
    \item dati, bidirezionale, per voce e dati
\end{itemize}
Ogni telefono ha una PROM dove sono predeterminati 21 canali per il controllo, il numero seriale e il numero di telefono. 
Il telefono trasmette queste informazioni in un pacchetto in broadcast per collegarsi alla stazione base più vicina.

Quando si effettua una chiamata, viene trasmesso tramite il canale di accesso il numero da chiamare e la propria identità.
Una volta che la richiesta raggiunge la stazione, questa comunica con il MTSO che cerca un canale libero per la chiamata.
Quando trovato, viene trasmesso il numero nel canale di controllo e il telefono passa al canale vocale in attesa di risposta.

\subsubsection{Seconda generazione - voce digitale}
Per la seconda generazione sono utilizzati 4 sistemi qui esposti.

\paragraph{D-AMPS}
\`E la seconda generazione di AMPS, orientata al digitale. 
La versione digitale utilizza le stesse frequenze di AMPS, quindi vengono divisi i canali tra digitali e analogici.
La ripartizione può cambiare dinamicamente in base al tipo di dispositivi presenti nella cella. 
Sta al MTSO della cella la gestione della distribuzione.

Per gestire l'aumento di carico, è stata prevista una nuova banda di frequenza. 

Il segnale vocale viene raccolto dal microfono, digitalizzato e compresso dal \textit{vocoder}.
Questo processo è molto importante per la telefonia mobile con D-AMPS perché offre un ottimo miglioramento utilizzando il TDM. 
[...]

\paragraph{GSM}
[...]

\paragraph{CDMA}
[...]

\paragraph{PDC}
Usato solo in Giappone, non approfondito.

\subsubsection{Terza generazione - voce e dati digitali}
Per la terza generazione si puntava ad un'unica tecnologia per semplificare la diffusione e lo sviluppo del dispositivi che dovevano utilizarla.
Ci sono state diverse proposte e dopo una selezione rimasero due possibilità: W-CDMA e CDMA2000.
Il primo utilizzava una modulazione a spettro distribuito a sequenza diretta, pensato per interagire con GSM, in modo da poter entrare nelle celle di quest'ultimo senza perdere le chiamate.
La seconda proposta si basava anch'essa sulla modulazione a spettro distribuito a sequenza diretta, ma non punta all'interazione con GSM. 

Nel frattempo alcuni operatori proposero alcuni schemi detti \textit{2.5G}; 
uno è EDGE, un GSM con un bit in più per baud. Il bit in più porta anche a più errori.
L'altra proposta è GPRS, una rete a pacchetti costruita sopra D-AMPS e GSM.
Questa permette di inviare/ricevere pacchetti IP in una cella vocale;
vengono riservati alcuni slot temporali al traffico di pacchetti e la stazione base definisce il numero e la posizione degli slot.
Gli slot disponibili sono divisi in canali logici, la stazione base determina l'associazione tra i canali logici e time slot.
Un canale logico è usato per scaricare i pacchetti dalla stazione base nella stazione mobile e ogni pacchetto indica il destinatario.

Per inviare un pacchetto IP, una stazione mobile chiede uno o più slot inviando una richiesta alla stazione base.
Se la richiesta arriva senza problemi, la stazione comunica all'apparecchio mobile la frequenza e gli slot che dovrà utilizzare per trasmettere il pacchetto.
Una volta arrivato alla stazione base, il pacchetto è trasferito su Internet attraverso una connessione via cavo.

\newpage
\section{Capitolo 3 - Strato data link}

\subsection{Progetto dello strato data link} % 3.1
Lo strato data link ha diverse funzioni, tra cui:
\begin{itemize}
    \item fornire un servizio di interfaccia per lo strato network
    \item gestire gli errori di trasmissione
    \item regolare il flusso dati 
\end{itemize}
Per svolgere le sue funzioni, lo strato data link riceve i pacchetti dallo strato network e li incapsula in frame.
Un frame contiene header, carico e coda.

\subsubsection{Servizi forniti allo strato network}
Il servizio principale è quello di trasferire i dati tra gli strati network di due macchine differenti.
Alcuni servizi forniti sono:
\begin{itemize}
    \item unacknowledged senza connessione
    \item acknowledged senza connessione
    \item acknowledged orientato alla connessione
\end{itemize}
Il primo consiste nell'invio di frame senza che la macchina di destinazione debba dare l'acknowledgement, ovvero la conferma della ricezione.
Non viene creata una connessione logica e non ci si assicura che il frame arrivi a destinazione.
Si utilizza quando gli errori di trasmissione sono limitati, così da permettere la correzione direttamente agli strati superiori e
quando si vuole una comunicazione real-time dove il ritardo è peggio di una ricezione di dati parzialmente errati (es: chiamate, stream video).

Il secondo offre una maggiore affidabilità in quanto è richiesto l'acknowledgement.
Se non viene ricevuto entro un certo intervallo, può essere rispedito il frame. 
Anche questo non usa una connessione logica. 
L'acknowledgement può essere richiesto direttamente dallo strato network, ma si presenta un problema di prestazioni.
Il strato network può richiedere la spedizione dell'intero pacchetto nel caso non arrivi l'acknowledgement, che non ha limiti di dimensioni.
Un frame invece è di dimensione ridotta e limitata, per cui è più facile gestire il reinvio del singolo frame rispetto al pacchetto intero.

Il terzo tipo è il più affidabile. Oltre alla richiesta di acknowledgement, deve stabilire una connessione con il destinatario prima di iniziare la trasmissione.
I frame sono numerati ed è garantito l'arrivo nell'ordine corretto.
Il trasferimento dei dati avviene in 3 fasi: stabilita la connessione, trasmissione dei frame, rilascio della connessione. 

\subsubsection{Suddivisione in frame}
Lo strato data link deve ricevere dallo strato fisico i dati sottoforma di bit e verificare che siano corretti ed eventualmente correggerli.
Per fare ciò viene suddiviso il flusso di bit in una serie di frame e viene calcolato il checksum (vai a §\ref{checksum}) per ogni frame.
Una volta giunto a destinazione il frame, viene ricalcolato il checksum e se è differente da quello del frame, lo strato sa che c'è stato un errore e prende i relativi provvedimenti.

La suddivisione non è un'operazione banale. Ci sono diversi metodi per farlo, spiegati di seguito.

\paragraph{Conteggio dei caratteri}
Questo metodo usa un campo dell'intestazione per indicare il numero di caratteri nel frame.
In questo modo quando viene letto il frame sa dove termina.
Il problema è che un errore può alterare il conteggio, mandando il destinatario fuori sincronia.
Anche utilizzando il checksum non è possibile sapere dove inizia il frame successivo.
Per questi problemi, il metodo non è più usato.

\paragraph{Byte stuffing}
Un secondo metodo utilizza un byte all'inizio e alla fine del frame come flag byte.
Di solito i byte utilizzati sono gli stessi.
Questo metodo permette di trovare il frame successivo nel caso un errore faccia perdere la sincronia.
Tuttavia il problema di questo metodo si presenta quando vengono trasmessi file binari, in quanto il valore del flag byte potrebbe essere presente nel frame.
Per risolvere questo problema è possibile usare la tecnica del Byte stuffing,
ovvero viene inserito un carattere di escape prima di ogni occorrenza nel frame del byte flag, in modo da distinguerli effettivamente dai flag;
lo strato data link di destinazione rimuoverà gli escape.

\paragraph{Bit stuffing}
Il Byte stuffing è limitato perché è legato a caratteri di 8 bit, ma se si usano codifiche diverse risulta un problema.

Con la nuova tecnica è possibile usare sia un numero arbitrario di bit, sia codifiche varie.
Ogni frame comincia e finisce con il gruppo di bit 01111110, di fatto un flag byte. 
Se nel flusso vengono letti 5 bit 1 consecutivi, viene messo un bit 0 in coda, mentre nella destinazione verrà rimosso.
Questa tecnica è detta bit stuffing.

\subsubsection{Controllo errori}
Problema: assicurarsi che i frame arrivino tutti a destinazione e nell'ordine corretto.\\
Un modo è quello di utilizzare un acknowledgement, positivo o negativo, per notificare l'arrivo del frame.
Tuttavia, anche l'acknowledgement può andare perso. Si utilizza quindi un timer che parte insieme all'invio del frame.
Se viene ricevuto l'acknowledgement, viene ignorato il timer, altrimenti allo scadere del tempo viene rispedito il frame.
Per evitare doppioni, i frame hanno un numero di sequenza in modo che se la destinazione aveva già ricevuto il frame possa ignorarlo.

\subsubsection{Controllo di flusso}
Il controllo del flusso consiste nella gestione della velocità di trasmissione dei frame,
in modo da non congestionare il destinatario se non riesce ad elaborare ciò che riceve abbastanza velocemente.

\subsection{Rilevazione e correzione errori} % 3.2
Gli errori di trasmissione è un problema difficile da evitare, in particolare per i collegamenti locali che sono ancora analogici.

\subsubsection{Codici per la correzione degli errori}
Per gestire gli errori ci sono due possibilità. 
O si aggiungono dei dati ridondanti di parità che permettono di ricostruire il contenuto del blocco (codifica a correzione d'errore),
o si utilizza abbastanza ridondanza da poter identificare la presenza di un errore, senza però poterla correggere, e vengono quindi ritrasmessi (codifica a rilevazione d'errore).
I canali affidabili come la fibra utilizzano la rilevazione, mentre quelli più soggetti a disturbi come il wireless usano la correzione.

Ma in cosa consiste un errore? \\
Un frame è composta da m bit di dati e r bit ridondanti, con un totale di n bit.
Gli n bit sono detti codeword. 
Date le due parole, si possono confrontare con lo XOR per vedere quanti bit sono differenti;
il numero di bit è detta la distanza di Hamming ed indica il numero di errori su singoli bit per convertire da una sequenza all'altra.

La rilevazione ela correzione degli errori dipende dalla distanza di Hamming.
Per trovare d errori è necessaria una codifica con d+1 di distanza;
in questo modo riesce a rilevarli, ma non a correggerli.
Per corregere d errori è invece necessaria una codifica con 2d+1 di distanza,
in modo che anche con d cambiamenti, la codeword originale rimane la più vicina a quella modificata ed è ricavabile univocamente.

Le codifiche di Hamming riescono a correggere solo errori singoli.
Si riesce a corregere gli errori burst sfruttando un trucco, ovvero inviando i dati di una matrice per colonna invece che per riga.

\subsubsection{Codifiche a rilevazione d'errore}
Su canali più affidabili, la rilevazione basta in quanto gli errori sono meno frequenti e risulta più efficiente rimandare i dati danneggiati.
Questo perché maggiore è la grandezza del blocco, maggiore è il numero di bit di controllo richiesti.

In alternativa alla tecnica della matrice, si usa la codifica polinomiale (CRC - Cycle Redundancy Check).
Questa tecnica considera le sequenze di bit come polinomi a coeficienti con valori uguali a 0 o 1.
Un frame di k bit è un polinomio di grado k-1 con k termini.\\
Esempio: 110001 -> $1*x^5+1*x^4+0*x^3+0*x^2+0*x^1+1*x^0$ -> $x^5+x^4+1$\\

Per utilizzare la codifica polinomiale, sorgente e destinazione devono definire un polinomio generatore G(x).
I bit di ordine più alto e più basso devono essere uguali a 1.
Il checksum di un frame è calcolabile se il polinomio relativo al frame è di grado maggiore (banalemente deve avere più bit) rispetto al polinomio generatore.
Si aggiunge un checksum alla fine del frame in modo che il relativo polinomio sia divisibile per G(x).
Se c'è un resto, significa che c'è stato un errore.

Calcolare in checksum:
\begin{enumerate}
    \item dato il grado g di G(x), aggiungere g bit con valore zero in coda al frame, ottenendo il polinomio M(x)
    \item fare la divisione M(x) / G(x)
    \item sottrarre il resto dalla M(x); ne risulta il frame con il checksum pronto alla trasmissione con polinomio T(x)
\end{enumerate}
Divisione e sottrazione vanno effettuate in modulo 2: la sottrazione equivale allo XOR, mentre la divisione sono fatte come nel binario normale ma con le differenze in modulo 2.

Questo metodo riesce a risolvere gli errori provocati da interferenza, rumore e distorsione.

\subsection{Protocolli data link elementari} % 3.3
Un frame è composto da 4 campi: kind, seq, ack, info.
I primi 3 contengono informazioni di controllo e fanno parte dell'header, mentre info contiene i dati effettivi.
Kind indica se ci sono dati nel frame. Seq contiene i numeri di sequenza. Ack contiene l'acknowledgement.

Lo strato network passa un pacchetto con un'intestazione di tipo network allo strato data link, il quale pone il pacchetto nel campo info di un frame.

\subsubsection{Simplex senza restrizioni}
Protocollo in cui i dati sono trasferiti in una sola direzione (simplex) e non ci sono altre restrizioni
(buffer infinito, strati pronti, tempo di elaborazione ignorabile, in canale non perde mai frame).
E' chiaramente un protocollo non realistico, solo d'esempio.

Il mittente invia i dati alla massima velocità possibile in un loop infinito.
Nel loop viene preso il pacchetto dallo strato network, costruisce il frame e instrada il frame. 
Il destinatario attende l'arrivo di un frame, salvato nel buffer;
viene prelevato dal buffer e passato il contenuto del frame allo strato network, infine torna ad attendere.

\subsubsection{Simplex stop-and-wait}
In questo protocollo si assume il traffico simplex e l'assenza di errori, ma con la restrizione più realistica di una velocità di elaborazione non più infinita.
Il problema da considerare quindi è la gestione del flusso, in modo che il mittente non inondi il ricevente con una velocità di trasmissione maggiore di quella di elaborazione.
Se ci vuole un intervallo t per elaborare un frame, il mittente non dovrebbe trasmettere più di un frame per t.
Se inoltre non ci sono meccanismi di buffer, il mittente non deve trasmettere il nuovo frame finché il precedente non è stato prelevato dallo strato fisico o verrebbe sovrascritto.
La soluzione al problema è l'utilizzo di un frame senza informazioni che viene rispedito al mittente quando il pacchetto è stato fatto passare allo strato network,
in modo da notificare il mittente per l'invio di un nuovo frame.
Il pacchetto funge da acknowledgement e blocca il mittente fino a quando non arriva il frame.
Questi protocolli basati sull'attesa dell'acknowledgement sono detti \textbf{stop-and-wait}.
Data la richiesta di far viaggiare i frame in entrambe le direzioni, è necessaria un'alternanza del flusso e un canale fisico half-duplex può bastare.

Il mittente prende il pacchetto dallo strato network, costruisce il frame e instrada il frame. 
A questo punto attende l'acknowledgement; quando lo riceve, manda un altro frame.
Il destinatario invece processa il frame e prima di tornare in attesa manda il frame di acknowledgement al mittente.

\subsubsection{Simplex per canali rumorosi}
Protocollo per una situazione normale, sempre simplex, dove i frame possono essere danneggiati o persi.
Se il frame è danneggiato, viene usato il checksum per verificare la correttezza.
Per far pronte al problema della perdita di frame, sia dati, sia di acknowledgement, si utilizza un timer e il numero di sequenza dei frame.
Il problema successivo è decidere quanti bit usare per il numero di sequenza.
L'unica ambiguità possibile è tra il frame stesso e il successivo, quindi è sufficiente un bit.

Il mittente prima memorizza in una variabile locale il numero di sequenza del successivo frame da inviare, poi crea il frame, lo instrada e fa partire il timer.
Rimane in attesa: riceve un acknowledgement positivo, o un acknowledgement con problemi, o il scade il timer.
Nel primo caso prende in carico il frame successivo, negli altri due viene rimandato il frame.
Il destinatario riceve il frame, controlla il numero di sequenza: 
se è valido, lo processa, lo passa allo strato network, ritorna l'acknowledgement e aggiorna la variabile del numero di sequenza.

\subsection{Protocolli sliding window} % 3.4
Questi protocolli sono utilizzati per le trasmissioni in entrambe le direzioni, full duplex.
Si possono usare due canali separati simplex, ma di solito quello di ritorno è sprecato; conviene usare un unico canale e gestire entrambe le direzioni.
Una miglioria successiva è la tecnica del piggy-backing, ovvero quando arriva un frame dati, non viene restituito subito il frame di acknowledgement, 
bensì viene aggiunto al frame di dati successivo passato dallo strato network, in modo da "risparmiare" un viaggio e sfruttare al meglio la banda.
Infatti aggiungere il campo ack nell'intestazione è più conveniente rispetto a creare un intero frame con sua intestazione, checksum e acknowledgement.
Il problema di questa tecnica è l'estendersi dell'attesa dell'acknowledgement.
Per quanto tempo deve aspettare lo strato data link prima di mandare l'acknowledgement in maniera indipendente?

I protocolli seguenti sono strettamente legati al buffer, in quanto il mittente avrà una "finestra d'invio", ovvero un insieme di frame che può inviare,
e il destinatario ha una "finestra di ricezione", ovvero un insieme di frame che può ricevere.
Le due finistre non devono essere grandi uguali e possono avere dimensione variabili.
Queste danno una maggior libertà di invio dei frame, ma il passaggio allo strato network deve comunque mantenere l'ordine.
I numeri di sequenza nella finestra d'invio indica i frame trasmessi o in transito, che sono attesa dell'acknowledgement.
Quando arriva un pacchetto dallo strato network il limite superiore aumenta di uno, mentre quando arriva un acknowledgement il limite inferiore aumenta di uno.
Se la finestra di invio contiene n frame, il mittente dovrà avere almeno n buffer per mantenere i frame fino all'arrivo dell'acknowledgement.

\subsubsection{Sliding window a 1 bit}
Questo protocollo utilizza una finestra di un bit, risultando quindi simile al protocollo stop-and-wait.
La differenza è che ora la trasmissione è full duplex.
Di conseguenza può accadere che entrambi i computer vogliano mandare un pacchetto,
creando ridondanza in quanto vengono mandati pacchetti duplicati senza che siano necessari.

\subsubsection{Go back N e Ripetizione selettiva}
Il tempo per trasmettere un frame sommato al tempo per ricevere l'acknowledgement a volte non è trascurabile (nei precedenti protocolli era considerato tale).
Infatti si può arrivare a sprecare fino al 90\% di tempo durante il quale il sorgente rimane in attesa per inviare un nuovo pacchetto.
Il problema deriva dalla richiesta di far attendere il sorgente.
Con la tecnica detta pipelining si attenua il problema, 
inviando n frame nell'intervallo totale di transito (dall'invio alla ricezione dell'ack) senza riempire completamente la finestra.
Il numero di frame inviabili indica la grandezza della finestra.
Maggiore è il ritardo di trasmissione, maggiore sarà la grandezza della finestra.
Il prodotto tra banda e ritardo di trasmissione indica la capacità della pipeline.
Usandola tutta, il sorgente opera a massima efficienza.
Dati: 
\begin{itemize}
    \item c - capacità del canale
    \item d - dimensione del frame
    \item T - tempo totale di propagazione
\end{itemize}
l'utilizzo della linea è uguale a d/(d+cT).
Se d<cT, l'efficienza sarà minore del 50\%.

Con il pipelining, se dei frame vengono danneggiati o persi si verificano diversi problemi.
Il destinatario non sa cosa fare con i frame seguenti a quello danneggiato.
Per ripristinare gli errori ci sono due tecniche, una delle quali è il go back N.

Questa tecnica richiede di scartare tutti i frame successivi a quello danneggiato senza mandare l'acknowledgement per questi.
In particolare il sorgente manda tutto in sequenza, non sapendo se arrivano errati a destinazione, finché non termina i frame della finestra.
Quando scade il timer dell'acknowledgement che non sarà ricevuto, il mittente rimanda i frame in sequenza a partire da quello danneggiato,
anche se i successivi erano corretti.
Il destinatario invece, quando riceve il frame danneggiato si rifiuta di accettare tutti i successivi finché non riceve quello con il numero di sequenza atteso.
Di fatto questo protocollo utilizza una finestra di ricezione con 1 frame.

L'altra tecnica per ripristinare gli errori è la ripetizione selettiva.
In questo caso viene scartato solo il frame danneggiato, mentre i successivi corretti vengono messi in un buffer.
Quando il sorgente va in timeout rimanda il frame danneggiato.
Il destinatario lo riceve e passa allo strato network il frame ricevuto più tutti quelli nel buffer, mantenendo l'ordine corretto e ritornando l'ack.
In particolare, quando il ricevente trova un frame danneggiato, viene mandato un NAK, un acknowledgement negativo.
Il NAK migliora le prestazioni in quanto triggera il sorgente a rimandare il pacchetto prima che scada il timer.
Se venisse perso il NAK, ci sarebbe comunque il timer del sorgente.
Questo protocollo utilizza una finestra di ricezione maggiore di 1.
La dimensione massima della finestra dovrebbe essere uguale alla metà della sequenza dei numeri;
invece il numero di buffer della destinazione deve essere uguale alla dimensione della finestra.

I due approcci dipendono molto dall'uso della banda e del buffer. 
Il primo si basa sulla banda, dovendo rimandare tutto, il secondo sul buffer, dato che salva i frame corretti in attesa di quello mancante.

\subsection{Esempi di protocolli} % 3.6

\subsubsection{HDLC - High-level Data Link Control}
Questo protocollo è orientato ai bit e utilizza il bit stuffing.
Il frame di questo protocollo ha il campo address, control, data e checksum.
Address indica il terminale; control è usato per i numeri di sequenza; 
data contiene le informazioni; checksum è il codice di ridondanza.
Il frame è delimitato dal flag 01111110.
[...]

\subsubsection{PPP - protocollo punto a punto}
Il PPP è un protocollo data link usato da internet.
Tra le caratteristiche ci principali ci sono:
\begin{itemize}
    \item metodo di framing
    \item protocollo per la gestione della connessione - LCP (Link Control Protocol)
    \item una modalità per negoziare le opzioni dello strato network in modo indipendente dalla sua implementazione
\end{itemize}

Il frame PPP assomiglia a quello HDLC, tuttavia è orientato ai caratteri, quindi usa il byte stuffing.
Il flag usato è sempre quello di HDLC; i caratteri di escape vengono aggiunti su tutto il frame (non solo sui dati)
dopo il calcolo del checksum e vengono tolti in ricezione prima del ricalcolo del checksum.
Ha il campo address sempre impostato a 11111111 per indicare che tutte le stazioni devono accettarlo;
segue il campo control che di default vale 00000011.
Dato che questi campi sono costanti, LCP permette di omettere questi campi nella configurazione.
Il campo protocol indica il tipo di pacchetto contenuto nel campo payload.
L'ultimo campo contiene il checksum.
[...]

\newpage
\section{Capitolo 4 - Sottostrato MAC}
Il sottostrato MAC riguarda i canali multiaccesso, ovvero i canali usati delle reti broadcast.
C'è bisogno di regolamentare l'accesso al canale in qualche modo.

\subsection{Il problema dell'assegnazione del canale} % 4.1
Come assegnare un singolo canale broadcast tra diversi utenti in competizione?

\subsubsection{Assegnazione statica}
Di solito per condividere un canale tra più utenti si usa il multiplexing a divisione di frequenza FDM.
La banda viene suddivisa in parti uguali le quali sono assegnate agli utenti. 
Ognuno ha una proprio frequenza, quindi non c'è interferenza tra loro.
FDM funziona bene se non ci sono troppi utenti e se il numero è abbastanza costante.
Se non lo è, ci sono dei problemi. 
Se gli utenti sono minori della divisione della banda, ci sarà uno spreco;
se sono di più, alcuni utenti non riusciranno a comunicare.

In generale, un'assegnazione statica è poco efficiente perché anche mantenendo costanti gli utenti,
quando non usano il canale quella banda rimane inutilizzata.
Anche con TDM la situazione non cambia molto.

\subsubsection{Assegnazione dinamica}
Ci sono 5 premesse riguardo il problema dell'assegnazione del canale.
\begin{itemize}
    \item Modello della stazione: n stazioni indipendenti che generano frame in trasmissione;
    quando viene generato un frame, la stazione attende finché non viene spedito
    \item Presupposto del canale singolo: un solo canale per trasmettere e ricevere
    \item Presupposto della collisione: due frame trasmessi assieme di sovrappongono creando distorsione e rendendo il frame non valido;
    le stazioni possono rilevare questo evento detto collisione e richiedere la ritrasmissione del frame
    \item Tempo continuo e Tempo diviso in intervalli: nel primo caso la trasmissione può avvenire in qualsiasi istante,
    mentre nel secondo il tempo è diviso in slot e la trasmissione di un frame coincide sempre con l'inizio di un intervallo
    \item Occupazione del canale verificabile o meno: le stazioni possono o meno verificare se un canale è occupato;
    se possono verificare, la trasmissione dipende dall'esito, se non possono mandano il frame a priori
\end{itemize}

\subsection{Protocolli ad accesso multiplo} % 4.2

\subsubsection{Aloha}
Aloha è un sistema sviluppato inizialmente per collegare le isole della Hawaii, basato su una trasmissione radio broadcast con singolo canale.
Ne esistono due versioni.

\paragraph{Aloha puro}
L'idea di base è quello di consentire agli utenti di trasmettere ogni qual volta ne avessero bisogno.
Anche se ci sono collisioni, la proprietà di feedback della trasmissione broadcast permette al trasmettitore di scoprire se il frame è danneggiato.
Se non è possibile ascoltare il canale, è necessario un sistema di acknowledgement.
Se il frame è stato distrutto, il trasmettitore attenderà per un tempo \textbf{casuale} prima di ritrasmettere il frame altrimenti si ripeterà la collisione.
I sistemi con un canale condiviso dove si possono generare conflitti si dicono sistemi a contesa.

I frame trasmessi sono tutti della stessa lunghezza e vengono inviati completamente a caso. 
Se anche un solo bit va in collisione, entrambi i due frame vanno buttati.
Non c'è modo di capire se c'è stato un conflitto parziale o totale.

\paragraph{Aloha slotted}
Alcuni anni dopo venne proposta l'alternativa slotted Aloha,
la quale permette di duplicare la capacità del sistema dividendo il tempo in intervalli discreti, dove ogni intervallo corrisponde un frame.
In questo sistema non viene inviato un frame in un momento a caso, ma solo all'inizio dell'intervallo successivo.
Questa soluzione riduce le collisioni, ma richiede un meccanismo di sincronizzazione per gestire l'invio dei frame solo all'inizio di un intervallo.

Questa tecnica fu rispolverata quando fu inventato l'accesso a internet via cavo, dovendo gestire un canale condiviso.

\subsubsection{Protocolli ad accesso multiplo con rilevamento della portante}
Con i protocolli Aloha si hanno molte collisioni.
Se invece le stazioni rimangono in ascolto di una portante è possibile migliorare le prestazioni.

\paragraph{CSMA persistente e non}
Un esempio di questi protocolli è il CSMA 1-persistente.
Una stazione prima di trasmettere ascolta il canale per sapere se è occupato.
Se lo è attende e appena si libera manda un frame;
in caso di collisione la stazione rimane in attesa di un intervallo casuale per poi rimandare il frame.
1-persistente indica che la stazione trasmette con probabilità 1 quando il canale è libero (cioè lo fa sempre).
Il problema è che il ritardo di propagazione potrebbe creare l'illusione di avere un canale libero,
quando in verità il canale è già stato occupato ma il segnale non ha ancora raggiunto la stazione che ne richiede l'utilizzo.
Anche con ritardo zero potrebbe verificarsi una collisione in quanto due stazioni potrebbero attendere contemporaneamente.
Questo protocollo risulta migliore dell'Aloha puro.

Un altro protocollo è detto CSMA non persistente, il quale se trova il canale occupato non rimane subito in attesa, bensì riprova dopo un intervallo casuale.
Si ha un migliore utilizzo del canale ma aumenta i ritardi.

Esiste anche il CSMA p-persistente, dove p indica la probabilità di trasmettere nel canale se è libero.
A differenza del 1-persistente, la probabilità sarà minore di 1, quindi potrebbe non trasmettere subito e rimandare a più tardi.

\paragraph{CSMA con rilevamento delle collisioni}
Esiste un miglioramento dei CSMA persistenti, con un protocollo detto CSMA/CD (collision detection).
In questo protocollo, quando una stazione inizia la trasmissione e rileva la collisione, termina subito la trasmissione;
dopo un intervallo di tempo casuale ritenta la trasmissione.
In questo modo si risparmia tempo e banda. Viene molto usato nel sottostrato MAC delle LAN.

Piccola nota: nessun protocollo del sottostrato MAC garantisce consegna affidabile.
Potrebbero non esserci collisioni, ma il ricevitore potrebbe comunque copiare in frame non correttamente.

\subsubsection{Protocolli senza collisione}
Nei seguenti protocolli si presuppone che ci siano N stazioni identificate da un indirizzo che va da 0 a N-1 e che il ritardo sia trascurabile.
Questi protocolli risolvono la contesa senza creare collisioni.

\paragraph{Protocollo a mappa di bit elementare}
In questo protocollo, ogni periodo di contesa è composto da N intervalli.
Ogni stazione indicherà tramite un bit se deve trasmettere un frame. 
Il bit viene posto nel rispettivo intervallo in base all'indirizzo della stazione (stazione 0 in 0, stazione N-1 in N-1).
Al termine degli N intervalli, tutte le stazioni sono a conoscenza di chi ha bisogno di trasmettere e lo fanno secondo l'ordine dell'indirizzo.
Essendo prestabilito l'ordine, non avverranno collisioni.
Al termine della fase di trasmissione, ci sarà un nuovo periodo di contesa dove si ripeterà il processo di "prenotazione".
Ogni stazione può porre il proprio bit "pronto" solo nel suo intervallo e può farlo se ha effettivamente il frame preparato.
Se la stazione diventa pronta ma il suo intervallo è passato, dovrà attendere la prossima fase di contesa.

Questo tipo di protocolli sono detti protocolli a prenotazione.

\paragraph{Conteggio binario}
Il problema del metodo della mappa è la richiesta del bit di controllo: se ci sono tante stazioni, sono richiesti tanti bit (uno per stazione).
Un'alternativa è quella di utilizzare indirizzi binari per le stazioni.
Una stazione che vuole trasmettere lo comunica agli altri tramite il proprio indirizzo, spedito sotto forma di stringa partendo dal bit più a sinistra.
Dato che gli indirizzi sono tutti lunghi uguali, i bit nella stessa posizione sono elaborati tramite OR: 
se il risultato è un 1, tutte le stazioni con bit 0 si arrendono;
poi si passa al confronto del bit successivo con le stazioni rimanenti e se risulta uno 0 si passa al bit successivo,
se un 1, si arrendono quelle con lo 0 e si prosegue, finché non rimane una stazione e sarà quella che spedirà il frame.
Questo protocollo è detto conteggio binario e chiaramente introduce un livello di priorità tra le stazioni (max priorità l'indirizzo più grande),
che in base alle situazioni può essere vantaggioso o meno.

Al momento è un protocollo inutilizzato nonostante la semplicità.

\subsubsection{Protocolli a contesa limitata}
Meglio i protocolli a contesa o senza collisioni?
Il primo è preferibile per il basso ritardo quando il carico è leggero, ma al crescere del carico peggiora l'efficienza.
Il secondo funziona all'opposto.

I protocolli a contesa limitata si pongono a metà strada tra i due.
Questi protocolli dividono le stazioni in gruppi (anche non esclusivi) e in ogni gruppo le stazioni competono tra loro per un determinato intervallo:
il gruppo 0 per l'intervallo 0, il gruppo 1 per l'1, e così via.
Il trucco sta nel ripartire le stazioni nel modo ottimale.
La soluzione migliore è quella di assegnare dinamicamente in base al carico.

\paragraph{Adaptive Tree Walk}
Questo metodo sfrutta gli alberi binari.
Nel primo intervallo di contesa (0), tutte le stazioni tentano di acquisire il controllo. 
Se non riescono perché c'è una collisione, le stazioni vengono divise in due gruppi e 
nel successivo intervallo (1) provano ad ottenere il canale quelle del secondo nodo.
Se la trasmissione avviene con successo, l'intervallo successivo (2) va al nodo 3, altrimenti si suddivide il 2 in due sottogruppi e così via.

A carico elevato si dovrebbe iniziare già a livelli più bassi dell'albero.

\subsubsection{Protocolli LAN Wireless}\label{problemiStazioni}
Esempio di LAN wireless: un ufficio con stazioni base (o access point) sparsi e collegate tra loro tramite cavi.
Regolando la potenza del segnale attorno a 3-4 metri, si ottiene una situazione dove le stanze sono considerabili come delle celle.
Una cella ha un unico canale che copre tutta la banda ed è disponibile a tutte le stazioni.
Nel caso della LAN wireless il problema non è il trasmettitore bensì il ricevente.
Infatti considerando delle stazioni con portata limitata, dove A raggiunge B, B raggiunge C, ma A e C non comunicano direttamente,
potrebbe accadere che A cerca di comunicare con B, mentre C che non sente A pensa sia tutto libero e cerca di comunicare con B. 
Il risultato è che A e C creeranno una collisione, danneggiando i frame.
Questo \textbf{problema} è detto \textbf{della stazione nascosta}.
All'inverso, se B trasmette ad A e C controlla la banda portante per trasmettere a D, siccome rileva la trasmissione di B pensa che anche D sia occupato.
In questo caso di dice \textbf{problema della stazione esposta}. 

\paragraph{MACA e MACAW}
MACA (Multiple Access with Collision Avoidance) è uno dei primi protocolli per LAN wireless.
Il trasmettitore invita il ricevitore ad inviare un piccolo frame per indicare che alle stazioni vicine che è occupato, 
in modo da poter inviare subito dopo il frame dati effettivo.
In particolare:
A vuole trasmettere a B; manda un RTS (request to send) a B che contiene la lunghezza del frame dati in arrivo;
B risponde con un CTS (clear to send) che contiene la lunghezza dei dati, copiata dal RTS.
In questo modo A può mandare il frame quando ha ricevuto la CTS.

Le stazioni vicine ad A che ricevono RTS devono stare in silenzio per attendere che CTS arrivi ad A.
Viceversa, le stazioni vicine a B che ricevono CTS devono stare in silenzio per permettere la trasmissione del frame dati.

In caso di collisione verrà effettuato un secondo invio con intervallo di tempo casuale.

Esiste poi la versione migliorata MACA per wireless, ovvero MACAW.
In questo protocollo è stato introdotto un frame ack dopo la trasmissione dati avvenuta con successo,
ed è stata aggiunta la possibilità di bloccare le stazioni vicine che stanno mandando un RTS quando ce n'è già uno in viaggio verso la stessa destinazione.

\subsection{Ethernet} % 4.3 TUTTO tranne 439
Gli standard più importanti:
\begin{itemize}
\item 802.3 - Ethernet
\item 802.11 - LAN wireless
\end{itemize}
Hanno sottostrati fisici e sottostrati MAC differenti, ma hanno la stessa interfaccia verso lo strato network.

\subsubsection{Cablaggio Ethernet}
Ethernet è il nome del cavo utilizzato per 802.3 e ne esistono 4 tipi.
Il modello più vecchio è il 10base5, o thick Ethernet.
Il cavo è piuttosto spesso e le connessioni sono realizzate mediante spine a vampiro (?).
Il nome indica che opera a 10Mps con segnali a banda base e sopporta segmenti lunghi fino a 500 metri.

Il secondo cavo è 10Base2 o thin Ethernet;
come per il precedente, dal nome si sa che opera a 10Mps con segnali a banda base e sopporta segmenti lunghi fino a 200 metri circa.
In questo caso le connessioni sono fatte mediante connettori BNC che formano giunzioni a T; sono più facili da usare e più affidabili.
Questo cavo è economico, semplice da installare, ma supporta solo segmenti di 185 metri e un massimo di 30 macchine.

I guasti sono un problema per le connessioni cablate; per questo esistono tecniche per rintracciare i guasti,
come la TDR (Time Domain Reflectometry), la quale usa un impulso per vedere se è tutto apposto.
Se ci sono guasti o ostacoli si genera un eco che torna indietro e cronometrando il tempo di ricezione dell'eco è possibile identificare la distanza dell'origine dell'eco.

Dal problema del tracciamento guasti, si è passati all'utilizzo di hub; le stazioni sono collegate agli hub tramite doppini non condivisi.
Questo hub non elabora il traffico.
Questa configurazione permette di aggiungere e rimuovere stazioni facilmente ed ha una facile individuazione le interruzioni della linea.
Tuttavia i cavi che partono dall'hub possono raggiungere solo i 100/200 metri.
Nonostante questo è diventato uno standard per la facilità di gestione e per l'uso dei cablaggi presistenti.
Lo schema presentato è detto 10Base-T.

Un altro tipo di cavi è il 10Base-F che utilizza le fibre ottiche.
Questa alternativa è costosa a causa del prezzo di connettori e terminatori, ma è immune alle interferenze e permette i collegamenti a lunghe distanze (1km).

\subsubsection{La codifica Manchester}
Utilizzare una codifica binaria corretta è un problema non indifferente, perchè vanno scelti valori che non possono creare ambiguità.
Deve essere ben chiaro quando si ha l'inizio e la fine di un bit.
Esistono due tecniche: la codifica di Manchester e la codifica di Manchester differenziale.

La prima utilizza un periodo di bit diviso in due intervalli uguali, dove l'1 binario è identificato da un picco di tensione nel primo intervello e un livello basso nel secondo intervallo.
Lo zero binario è l'opposto.
Il cambio di tensione in mezzo al periodo di bit permette al ricevitore di sincronizzarsi con il trasmettitore;
tuttavia occupa il doppio della banda rispetto alla codifica elementare.

La codifica di Manchester differenziale è un'alternativa dove un 1 binario è identificato dall'assenza di cambio di tensione tra un periodo di bit e un altro,
mentre se avviene una transizione identifica uno zero.
Questa codifica è più complessa ma ha una maggiore immunità ai rumori.
Tuttavia Ethernet usa la Manchester base.

\subsubsection{Il protocollo del sottostrato MAC Ethernet}
Esistono due varianti di frame: quello DIX Ethernet e quello dello standard IEEE.
Lo standard apporta solo delle piccole modifiche a due campi (type diventa lenght, preamble viene ridotto),
tuttavia DIX aveva già preso piede a tal punto che pochi erano disposti a passare al nuovo standard.
Tuttavia il campo type prima della creazione dello standard era sempre maggiore di 1500,
quindi se è più corto viene considerato come campo lenght dello standard.
Con questo compromesso si riuscì ad usare entrambi i frame.

Più nello specifico, il frame DIX è composto da:
\begin{itemize}
    \item preamble
    \item indirizzo di destinazione
    \item indirizzo d'origine
    \item type
    \item dati
    \item riempimento
    \item checksum
\end{itemize}
Preamble è di 8 byte e contiene lo schema di bit 10101010.

I due indirizzi sono di 6 byte. In particolare l'indirizzo di destinazione ha il bit più a sinistra che identifica un indirizzo ordinario (0) o un indirizzo di gruppo (1).
Con l'indirizzo di gruppo è possibile far ascoltare a molte stazioni un singolo indirizzo e tutte lo ricevono (trasmissione multicast).
Se l'indirizzo è composto da soli 1 è riservato alla trasmissione broadcast.

Type di 2 byte indica al ricevitore cosa fare con quel frame.

I dati raggiungono i 1500 byte di massimo; è inoltre necessario che il frame in totale sia lungo almeno 64 byte, per distinguere dai frame danneggiati.
Inoltre la lunghezza minima serve per dare il tempo di impedire la trasmissione di un frame quando viene rilevata la possibilità di collisione.
Maggiore è la velocità della rete, maggiore deve essere la lunghezza minima del frame.

Il checksum di 4 byte e contiene il checksum CRC per rilevare (ma non correggere) gli errori.

\subsubsection{Algoritmo di backoff esponenziale binario}
L'algoritmo di backoff esponenziale binario è utilizzato per gestire l'attesa casuale dopo una collisione. 
\`E stato scelto perché si adatta in base al numero di stazioni che tentano di trasmettere.
L'algoritmo assicura un basso ritardo quando si hanno poche collisioni e una gestione accettabile quando avvengono molte collisioni. 

L'algoritmo procede in questo modo: 
dopo una collisione il tempo viene diviso in intervalli lunghi quanto il tempo di propagazione di andata e ritorno nel caso peggiore (2t);
ogni stazione aspetta 0 o 1 intervalli temporali prima di riprovare;
se due stazioni collidono perché usano lo stesso intervallo, aumenta la scelta degli intervalli casuali (0, 1, 2, 3);
ad ogni passo si continua ad aumentare il numero di intervalli d'attesa, che andrà da 0 a $2^i-1$, dove i indica il numero di collisioni.
L'algoritmo ha come tetto massimo 10 collisioni, per un totale di 1023 intervalli. Se ci sono ancora collisioni, a 16 viene lanciato un errore.

\subsubsection{Prestazioni di Ethernet}
[...]

\subsubsection{Ethernet commutata}
Al crescere del numero di stazioni, il traffico aumenta e l'aumento della velocità non basta a risolvere il problema.
La soluzione è lo switch (commutatore), che ha da 4 a 32 schede di linea, le quali hanno da 1 a 8 connettori, di solito collegati a doppini 10base-T verso i computer.

Una stazione che vuole trasmettere un frame Ethernet, prima invia un frame standard allo switch, il quale controlla se la destinazione è collegata alla stessa scheda di linea.
Se è nella stessa scheda, passa il frame direttamente, altrimenti viene passato alla scheda corretta.

Problema: se due macchine trasmettono sulla stessa scheda? \\
Ci sono due possibilità.
Se la scheda è costruita con le porte che formano una LAN locale, le collisioni vengono rilevate e gestite come in una rete CSMA/CD.
In questo modo è possibile una sola trasmissione per scheda, ma più trasmissioni in parallelo su schede diverse.
Ogni scheda costituisce il proprio dominio di collisione.

La seconda possibilità prevede un buffer per ogni porta che memorizza i frame in arrivo.
Quando ottiene tutto il pacchetto può controllare se il destinatario è nella stessa scheda o se serve spostarlo nella scheda appropriata.
Ogni porta è un dominio di collisione separato, quindi non ci sono collisioni.

\subsubsection{Fast Ethernet}
Nonostante l'aumentare della velocità, l'utente non è mai soddisfatta. 
Vennero allora proposte due LAN ottiche su topologie ad anello: FDDI e Fibre Channel.
Non ebbero molto successo, ma aprirono la strada ad una maggiore velocità.
Lo standard infatti decise di mantenere il 802.3 ma con velocità superiore, in modo da mantenere la compatibilità con le LAN esistenti.
Venne così creato Fast Ethernet (o anche il poco usato 802.3u). 
Di fatto la differenza sta nel tempo di bit ridotto da 100 a 10 nanosecondi.
Per questa versione era tollerata solo l'architettura 10base-T. Con quali cavi?\\
Il doppino cat-3 era una prima scelta data la sua diffusione, tuttavia non riusciva a trasportare 200 Megabaud (ovvero 100 Mbps con codifica Manchester) per 100 metri, come richiesto dal 10Base-T.
Venne quindi permesso il cat-3, ma consigliato il cat-5 e la fibra ottica. Abbiamo quindi, rispettivamente, 100Base-T4, 100Base-TX, 100Base-FX, con le ultime due full duplex a 100Mbps.

Lo schema Cat 3 necessita di 4 doppini: uno in ricezione, uno in trasmissione e gli altri due si adeguano alla direzione di trasmissione.
I segnali trasmessi sono ternari, cioè possono contenere 0,1 o 2. 
In questo modo si riesce a raggiungere la velocità obiettivo di 100 Mbps. Questo schema è chiamato 8B/6T.

Il modello basato sul Cat 5 è più semplice ed utilizza solo due doppini, uno in ricezione e uno in trasmissione.
In questo caso viene usato uno schema chiamato 4B/5B.
Questo sistema è full duplex, ovvero le stazioni possono trasmettere e ricevere contemporaneamente a 100 Mbps.

Il modello che utilizza la fibra ottica usa due cavi multimodali, uno per direzione.
Quindi il sistema è full duplex con 100 Mbps in ogni direzione e può raggiungere 2 km tra stazione e hub.
Per i modelli 100Base-T è possibile utilizzare sia switch che hub;
invece il modello a fibra ottica consente solo lo switch dove ogni cavo collegato crea un dominio di collisione verso se stesso. 

\subsubsection{Gigabit Ethernet}
Dopo la Fast Ethernet iniziarono a lavorare su una Ethernet ancora più veloce, ovvero la gigabit Ethernet.
Anche in questo caso si puntava ad avere una trasmissione più veloce mantenendo la compatibilità con le versioni precedenti.
Le configurazioni gigabit Ethernet sono tutte punto a punto, di conseguenza ogni stazione è collegata ad un solo hub e switch.
Sono supportate sia il full duplex che l'half duplex.
Quella normale è la full duplex, utilizzata quando c'è uno switch centrale collegato al computer alle stazioni del perimetro.
Tutte le linee hanno buffer e non è possibile avere quel collisioni, quindi non è necessario controllare se il canale è già utilizzato e di conseguenza non si utilizza il protocollo CSMA/CD. 
Si utilizza la half duplex quando i computer sono collegati ad un hub; 
in questo caso le collisioni sono ancora possibili quindi si utilizza il protocollo CSMA/CD.
Data la velocità di trasmissione, un frame è trasmesso così velocemente da limitare la distanza a 25 metri.
Questo è inaccettabile, di conseguenza sono state aggiunte due funzionalità dallo standard.
La prima è chiamata \textbf{Carrier extension}, aggiunge i dati di riempimento dopo il frame normale e viene rimosso quando viene ricevuto. 
Essendo una modifica hardware non sono richiesti cambiamenti al software. 
La seconda funzionalità è detta \textbf{Frame bursting} e permette di inviare una sequenza concatenata di più frame in una sola trasmissione;
se non viene raggiunta la dimensione di 512 Byte, viene compensata dal metodo sopracitato;
in questo modo si arriva ad un raggio di 200 metri un valore già più accettabile.
Esistono 4 tipi di configurazione che utilizzano cavi diversi: 1000Base-SX/LX/CX/T, le prime due con fibra, le ultime due con diversi tipi di doppini.

\subsubsection{Retrospettiva su Ethernet}
Punti vincenti: semplicità e flessibilità.

Semplice si traduce in affidabile, economico e facile da mantenere.
Flessibile in quanto funziona con TCP/IP ed è in grado di evolversi dove serve.

\subsection{LAN Wireless} % 4.4 TUTTO tranne 444

\subsubsection{La pila di protocolli 802.11}
I protocolli utilizzati dalle varianti 802 sono tutti simili.
Lo strato fisico è simile a quello OSI, lo strato datalink è suddiviso in due o più sottostrati.
In 802.11 il sottostrato MAC gestisce l'allocazione del canale, il sottostrato LLC nasconde le differenze tra le varianti di 802 in modo da renderle indistinguibili allo strato network.

\subsubsection{Lo strato fisico di 802.11}
[...]

\subsubsection{Il protocollo del sottostrato MAC di 802.11}
Il sottostrato MAC di 802.11 si differenzia leggermente da quello di 802.3, in quanto l'ambiente wireless complica le cose.
Per esempio ci sono i problemi della stazione esposta e della stazione nascosta (§\ref{problemiStazioni}).
Inoltre le trasmissioni sono quasi tutte hal duplex.
Per questi motivi non viene utilizzato CSMA/CD, bensì una variante detta CSMA/CA, ovvero Collision Avoidance.

In particolare, 802.11 supporta due modalità operative: 
DCF (Distributed Coordination Function), che non utilizza nessun controllo centrale,
e PCF, dove invece la stazione base controlla l'intera cella.

Quando viene usato DCF, si usa CSMA/CA che controlla sia il canale fisico, sia quello virtuale.

Questo protocollo rileva la portante prima della trasmissione e usa il backoff esponenziale dopo le collisioni, 
a differenza di CSMA/CD, il backoff di partenza è casuale e non attende una collisione per essere settato.

[...]


\subsubsection{Servizi}
Lo standard definisce 9 servizi che ogni LAN wireless deve fornire, 5 di distribuzione e 4 di stazione.
Quelli di distribuzione riguardano l'appartenenza alla cella e l'interazione con le altre celle, mentre quelli di stazione si occupano delle attività dentro la cella.
I servizi sono:
\begin{itemize}
\item Associazione - utilizzato dalle stazioni mobili per collegarsi alle stazioni base
\item Separazione - si interrompe la relazione tra le due stazioni
\item Riassociazione - la stazione mobile cambia la stazione base preferita (es: per cambiare cella)
\item Distribuzione - indica come saranno instradati i frame verso la destinazione
\item Integrazione - traduce dal formato 802.11 al formato richiesto dalla destinazione
\item Autenticazione - solo le stazioni autenticate possono trasmettere i dati
\item Invalidamento - invalida una stazione precedentemente autenticata che vuole lasciare la stazione
\item Riservatezza - le informazioni devono essere cifrate
\item Trasferimento dati - per il trasferimento
\end{itemize}


\subsection{Commutazione nello strato data link} % 4.7 TUTTO tranne 476
\`E possibile connettere più LAN tramite dispositivi detti bridge, che operano nello strato data link.
I bridge esaminano gli indirizzi dello strato datalink per l'instradamento senza esaminare il carico utile, permettendo di trasportare diversi tipi di pacchetto.
I router all'opposto instradano in base agli indirizzi del pacchetto.

Alcuni motivi per creare LAN differenti che vengono poi connesse tra loro sono:
\begin{itemize}
\item rendere indipendenti le LAN dei dipartimenti diversi
\item collegare aziende su edifici diversi, lontani tra loro
\item suddividere una LAN logica in più LAN fisiche per gestire meglio il carico
\item per collegare più LAN suddivise per i limiti di distanza (es: 2,5 Km in caso di Ethernet)
\item per garantire una maggiore affidabilità in caso di nodi difettosi
\item per ottenere una maggiore sicurezza dell'azienda
\end{itemize}

\subsubsection{Bridge tra due 802}
Come funziona un bridge?
Un pacchetto dallo strato di rete viene passato allo strato LLC che aggiunge l'intestazione relativa,
poi passa al sottostrato MAC dove viene aggiunta la sua intestazione, per esempio 802.11;
infine giunge allo strato fisico fino ad arrivare alla stazione base, dove viene rilevata la richiesta di passaggio tra due LAN di tipi diversi.
Il passaggio avviene tramite il bridge, che "traduce" il frame risalendo gli strati del bridge, fino a riscendere per passare allo strato fisico della seconda LAN.
Purtroppo non è così banale, in quanto ci sono diversi problemi.
Ad esempio i formati dei frame differiscono, richiedendo una conversione particolare;le due LAN possono trasmettere a velocità diverse;
inoltre c'è la diversa lunghezza dei frame in base al tipo di 802; un'altra questione è la sicurezza, in quanto alcune versioni supportano la crittografia, mentre altri no; infine la qualità del servizio, che viene garantito in modi diversi.

\subsubsection{Internetworking locale}
Come già accennato, i bridge possono essere usati per connettere LAN anche dello stesso tipo.
In questo caso, i bridge accettano tutti i frame in arrivo, ma scartano quelli che appartengono già alla stessa LAN,
ovvero quei frame che non hanno bisogno di attraversare il bridge per cambiare LAN.
Nel decidere dove e se inoltrarli, il bridge utilizza l'indirizzo di destinazione e lo confronta con una tabella delle destinazioni.
Appena creata la connessione le tabelle sono vuote e il bridge manda il frame a tutte le LAN tranne a quella di input;
con il tempo riesce a riempire la tabella con gli indirizzi corretti e potrà inviare solo alla LAN che contiene la stazione richiesta.
Questo è detto algoritmo di apprendimento all'indietro.
In particolare la costruzione avviene salvando gli indirizzi della sorgente, memorizzando in che LAN si trova.

\subsubsection{Bridge spanning tree}
Per aumentare l'affidabilità è possibile collegare più LAN con bridge paralleli, tuttavia questo crea anelli nella topologia.
Per evitare il problema, viene costruito uno spanning tree, un grafico ad albero che evita i percorsi ad anello.

\subsubsection{Bridge remoti}
Delle LAN distanti possono essere connesse tra loro tramite bridge remoti,
ovvero una coppia di bridge che sono in comunicazione tra loro tramite una linea punto a punto.

\subsubsection{Ripetitori, hub, bridge, switch, router, gateway}
Nonostante la funzione simile, vale la pena confrontare ripetitori, hub, bridge, switch, router, gateway.
Innanzitutto, operano su strati diversi:
ripetitori e hub nel fisico, bridge e switch nel data link, router nel network, gateway nel trasporto e applicazioni (due tipi diversi).

\newpage
\section{Capitolo 5 - Strato network}

\subsection{Architettura dello strato network}

\subsection{Algoritmi di routing} % tutto tranne Dijkstra in 522, 525, 528 a 5211

\subsubsection{Principio di ottimalità}

\subsubsection{Routing basato sul percorso più breve}

\subsubsection{Flooding}

\subsubsection{Routing basato sul vettore delle distanze}

\subsubsection{Routing basato sullo stato dei collegamenti} % no elaborazione nuovi percorsi

\subsubsection{Routing gerarchico}

\subsubsection{Routing broadcast}

\subsection{Algoritmi per il controllo della congestione} 

\subsection{Qualità del servizio}

\subsubsection{Requisiti}

\subsubsection{Tecniche per una buona qualità}

\paragraph{Sovradimensionamento}

\paragraph{Utilizzo dei buffer}

\paragraph{Traffic shaping}

\paragraph{Leaky bucket}

\paragraph{Token bucket}

\subsection{Collegamento tra reti}

\subsubsection{Differenze tra le reti}

\subsubsection{Connessione tra le reti}

\subsubsection{Circuiti virtuali concatenati}

\subsubsection{Collegamento tra reti senza connessione}

\subsubsection{Routing in una internetwork}

\subsection{Lo strato network in internet}

\subsubsection{Il protocollo IP}

\subsubsection{Gli indirizzi IP}

\subsubsection{Protocolli di controllo internet}

% no rarp bootp si dhcp

\subsubsection{OSPF}

\subsubsection{BGP}

\subsubsection{Internet multicasting}

\subsubsection{IPv6}

\newpage
\section{Capitolo 6 - Strato trasporto}
Il livello di trasporto si basa sul livello di rete per fornire il trasporto dei dati tra due macchine secondo il livello di affidabilità desiderato e indipendentemente dalle reti fisiche. 
L'obiettivo finale è fornire un servizio efficiente, efficace ed affidabile ai suoi utenti.
Per fare ciò usa i servizi forniti dallo strato di rete. L'hardware/software usato per svolgere il lavoro è detto \textbf{entità di trasporto}.

Per molti aspetti lo strato trasporto può sembrare simile a quello network, ma il fatto è che questo strato è essenziale per garantire affidabilità che lo strato network, basato sulla rete, non può dare. 

Grazie alle primitive fornite dallo strato, i programmatori possono scrivere codice senza preoccuparsi della sottorete.

In seguito verrà usato TPDU (transport protocol data unit) per indicare i messaggi inviati da un'entità di trasporto ad un'altra. 
Quindi, riprendendo gli altri "contenitori" degli altri strati, avremo TPDU dentro un pacchetto, il quale è dentro un frame
(trasporto -> network -> datalink).
Ogni carico utile di ogni livello ha la propria intestazione. 

\subsection{Richiesta connessione e protocollo Three-way Handshake}

Il Three-way handshake è un protocollo che entra in gioco quando si deve stabilire una connessione.
Infatti stabilire una connessione è un'operazione tutt'altro che facile.
Al normale "percorso" CONNECTION REQUEST - CONNECTION ACCEPTED, la rete può perdere, ritardare, corrompere o duplicare i pacchetti, creando diversi problemi.
In particolare, l'esistenza dei duplicati ritardati è il nodo centrale del problema e può essere affrontato in diversi modi.
Una possibilità è l'utilizzo di indirizzi di trasporto monouso oppure si può assegnare ad ogni connessione un identificatore inserito in ogni TDPU.
Entrambe le possibilità hanno diversi problemi.

La soluzione è cercare di distruggere i pacchetti obsoleti rimasti in circolo, impostando una durata massima di vita del pacchetto.
Il valore massimo di durata può essere prefissato utilizzando una o più tecniche tra le seguenti:
\begin{itemize}
\item progettazione di sottoreti limitate che impediscono ai pacchetti di essere ripetuti ciclicamente
\item inserimento di un contatore di salti in ogni pacchetto che viene decrementato ad ogni salto e se raggiunge lo zero viene scartato
\item applicazione di un contrassegno temporale in ogni pacchetto; verrà scartato se diventa troppo vecchio secondo un tempo stabilito
\end{itemize}
Oltre al pacchetto, anche i suoi acknoledgment devono essere distrutti.
Consideriamo quindi un valore T che indica il tempo dopo il quale si può essere certi che tutte le tracce del pacchetto sono scomparse (sia pacchetto che acknoledgement).
La sorgente etichetta i segmenti con numeri di sequenza che non verranno riutilizzati per T secondi.
In questo modo ci sarà un unico pacchetto con quel numero di sequenza in sospeso.

Nel caso di malfunzionamento, è possibile far rimanere le entità inattive per T secondi in modo da far scadere gli eventuali segmenti vecchi, così da essere sicuri di non usare numeri di sequenza già utilizzati.
Tuttavia su reti complesse non conveniva, quindi fu proposto un orologio per ogni host implementato come contatore binario che abbia tanti bit quanti quelli del numero di sequenza.
Quando viene instaurata la connessione, i k bit di ordine più basso dell'orologio sono usati come primo numero di sequenza, quindi ogni connessione inizia con numeri diversi.
Una volta stabilito il primo numero di sequenza, si può utilizzare un qualsiasi protocollo sliding window.

Il metodo dell'orologio risolve il problema dei segmenti duplicati, ma non c'è modo si ricordare i numeri tra una connessione e l'altra, quindi non sappiamo se un segmento di richiesta di connessione sia duplicato o meno.
La soluzione è il three-way handshake che richiede la verifica reciproca da parte dei peer utilizzando tre messaggi.
Il primo host manda la richiesta di connessione con un numero di sequenza x; l'host 2 risponde con un ack che conferma x e contiene il suo numero di sequenza iniziale. L'host 1 allora invia il primo segmento dati e conferma a sua volta la scelta del numero di sequenza iniziale dell'host 2.
Nel caso di richiesta di connessione duplicata, l'host 2 reagisce normalmente, ma al terzo messaggio l'host 1 rifiuta il tentativo di connessione.
Se invece si hanno sia la richiesta che l'ack ritardati, l'host 2 reagisce normalmente restituendo il numero y, successivamente l'host riceve il secondo segmento ritardato che ha però un ack su un numero diverso da y, per cui capisce che è un duplicato.

\subsection{Rilascio della connessione}
Il rilascio della connessione è più semplice e può essere simmetrico o asimmetrico.
In quello asimmetrico, una delle due parti interrompe la connessione; è improvviso e può far perdere di dati.
Il rilascio simmetrico tratta la connessione come se fosse composta da due connessioni separate unidirezionali, quindi le rilascia separatamente.
In questo caso, anche se una delle due parti ha inviato il pacchetto DISCONNECT, può continuare a ricevere dati.

Anche per il rilascio conviene usare il three-way handshake, anche se in questo caso non è infallibile.
Ogni messaggio passa la richiesta di disconnessione e il ricevente deve confermare con una richiesta di rilascio; infine il primo risponde con l'ack.
in questo caso, ogni messaggio ha un timer per triggerare la rispedizione nel caso qualcosa vada storto.

\subsection{Introduzione all'UDP}
UDP (User Datagram Protocol) è un protocollo di trasporto senza connessione, permette cioè di inviare datagrammi IP senza dover stabilire una connessione.
UDP trasmette segmenti con un'intestazione di 8 byte seguita dal carico utile.
L'intestazione contiene le porte dell'origine e della destinazione.
Il campo UDP lenght include l'intestazione e i dati, mentre UDP checksum contiene il checksum.

UDP non si occupa del controllo del flusso, degli errori o della ritrasmissione.

Questo protocollo è particolarmente utile per il multimediale (streaming) e per le situazioni client/server,
dove è richiesta una risposta breve ad una breve richiesta al server.
Se non viene ricevuta la risposta, allora va in timeout e riprova.
Questo tipo di utilizzo viene effettuato dal DNS.

\subsection{TCP}

\subsubsection{Introduzione}
TCP (Transport Control Protocol) è un protocollo di trasporto creato per fornire affidabilità per un internetwork inaffidabile.
Un internetwork ha diversi parametri che possono variare e TCP cerca di adattarsi dinamicamente.
Un'entità di trasporto TCp riceve i dati dell'utente, li suddivide in pezzi di dimensione massima uguale a 64KB e invia ogni pezzo in un datagramma 
IP autonomo.
Nel ricevente i datagrammi vengono usati per ricostruire il flusso di byte originali. 
TCP ha il compito di segnalare gli errori, richiedere la ritrasmissione e riordinare i datagrammi se non sono nell'ordine corretto.

\subsubsection{Modello di servizio di TCP}
Il servizio TCP è ottenuto creando punti finali da parte del mittente e ricevente, ovvero i socket.
Ogni socket ha un indirizzo composto dall'indirizzo IP dell'host e da un numero di 16 bit locale all'host, che indica la porta.
Per avere un servizio è necessario stabilire una connessione tra i due socket.

Un socket supporta più connessioni alla volta e una connessione è identificata dalla coppia dei due socket utilizzati.

I numeri di porta inferiori a 1024 sono le well-known ports, porte speciali dedicate ai servizi standard.

Tutte le connessioni TCP sono full-duplex punto a punto. Non supporta né il broadcsting, né il multicasting.

Una connessione TCP è un flusso di byte e non di messaggi, quindi un messaggio può essere trasmesso spezzato in blocchi di byte più piccoli o con altri messaggi. 

TCP ha la capacità di decidere se inviare subito i dati ricevuti da un'applicazione o se salvarli in un buffer per raggrupparli e inviarli insieme ad altri.
L'applicazione può avere però richieste particolare e chiedere che sia spedito subito tramite il flag PUSH.

\subsubsection{Protocollo TCP}
Una funzionalità importante del protocollo è il fatto che ogni byte ha un proprio numero di sequenza a 32bit.

I dati vengono scambiati sotto forma di segmenti.
Un segmento consiste di un'intestazione di 20 byte seguita da 0 (ack) o più byte di dati.
Sta a TCP decidere la grandezza massima dei segmenti e può decidere se dividere o combinare i messaggi.
Il limite superiore però è di 65615 byte, che deve starci nel carico utile di IP.
Ogni rete ha un MTU (Maximum Transfert Unit) e il segmento deve stare sotto la soglia.
Di solito è di 1500 byte.

Le entità TCP usano il protocollo sliding window.

\subsubsection{Intestazione TCP}
L'intestazione di un segmento è di 20 byte.
Due campi sono dedicati alla porta d'origine e a quella di destinazione.
I campi \textit{numero di sequenza} e \textit{numero di acknowledgement} svolgono le solite funzioni.
Il campo \textit{lunghezza dell'header TCP} indica quante parole di 32 bit sono contenute nell'intestazione; 
è necessario perchè il campo options ha una lunghezza variabile.
Seguono 6 bit inutilizzati e 6 bit per 6 flag, come URG (puntatore urgente), ACK (acknowledgement è valido), PSH (push), RST (reimposta la connessione), SYN (stabilisce una connessione), FIN (rilascia la connessione).
Il campo successivo \textit{window size} indica la dimensione della finestra per lo sliding window e in particolare quanti byte possono essere inviati a partire da quello che ha ricevuto l'acknowledgement.
Seguono il campo checksum e l'urgent pointer.
Una volta finita l'intestazione, sono presenti il campo \textit{options} per opzioni aggiuntive e i dati effettivi.

\subsubsection{Connessione TCP}
Le connessioni vengono stabilite secondo il three-way handshake.
Un host richiede la connessione inviando un segmento con bit SYN a 1 e ACK a 0 e attende la risposta.
L'host ricevente controlla se alla porta indicata nel frame è in ascolto; in caso negativo risponde rifiutando la connessione, 
altrimenti risponde con un segmento di acknoledge per dare il via libera al primo host, che manda il segmento di dati.

Se due host tentano una connessione sugli stessi socket, solo una delle due andrà a buon fine in quanto i socket sono identificativi della connessione.

\subsubsection{Rilascio connessione TCP}
Il rilascio avviene in maniera simmetrica, dove ogni parte può inviare un segmento con il bit FIN impostato per dire che ha finito di trasmettere e può essere chiusa la connessione.
Nel senso opposto può continuare la trasmissione finché non termina e viene rilasciata del tutto la connessione.

Per rilasciare la connessione servirebbero 4 segmenti (2 FIN e 2 ACK), ma è possibile raggruppare il primo ACK con il secondo FIN in modo da averne solo tre.

Se ad un FIN non arriva la risposta, un timer rilascia la connessione nella direzione del FIN inviato.

\newpage
\section{Capitolo 7 - Strato applicazione}

Lo strato applicazione e dove si trovano effettivamente le applicazioni.
Ci sono comunque dei protocolli di supporto per permettere alle applicazioni di funzionare.
Uno di questi è il DNS.

\subsection{DNS}

Il DNS (Domain name system) è un protocollo per la gestione dei nomi.
I siti web e le altre risorse possono essere accedute direttamente tramite l'indirizzo IP,
ma non risulta molto user-friendly in quanto per l'utente è difficile memorizzare l'indirizzo della risorsa richiesta.
Il DNS serve per tradurre gli indirizzi IP in nomi comprensibili e viceversa.
Infatti, se per l'utente il nome è più comprensibile, il network comprende solo l'indirizzo IP, per cui è richiesta la traduzione inversa da nome a indirizzo.
Un altro problema che ha portato alla creazione del DNS era la necessità di un sistema centralizzato, che permettesse di gestire i nomi senza avere duplicati.

Il DNS quindi è un sistema centralizzato con un database distribuito dove viene implementato lo schema gerarchico dei nomi basato su dominio. 
Viene utilizzato principalmente per mappare indirizzi IP e nomi del relativo host.
Per mappare un nome con il suo indirizzo IP, viene chiamata una procedura detta \texttt{resolver} con il nome come parametro.
Questa invia la query al server DNS e viene ritornato l'indirizzo IP; sia la query, sia la risposta sono spediti come pacchetti UPD.

La gerarchia dei nomi è divisa in diversi livelli. 
Internet è diviso in più di 250 domini di primo livello contenenti i vari host. 
Ogni dominio è partizionato in sottodomini, anch'essi partizionati ecc.
Il primo livello è distinto tra generici (com, org, edu, ecc) e nazioni (it, uk, jp, ecc).
Il secondo livello spesso indica l'azienda.
Il nome di un dominio può essere assoluto o relativo.
Se termina con il punto è assoluto; se è relativo, il reale significato dipende dal contesto.
I nomi sono case-insensitive e di lunghezza massima di 255 caratteri.

Ogni dominio può essere associato ad un insieme di record delle risorse.
Quando il DNS riceve un nome, restituisce i record associati, tra cui quello che indica l'indirizzo IP.
Un record è identificato dalla quintupla:\\
\texttt{Domain\_name Time\_to\_live Class Type Value}

Il Type A è il più importante in quanto è il record che contiene l'indirizzo IP. Questo record può non essere univoco.

Il server del DNS non è unico, altrimenti verrebbe sovraccaricato. Quindi i nomi sono divisi in zone, che risiedono su server diversi. 

\newpage
\section{Capitolo 8 - Sicurezza}

\subsection{Crittografia} % 8.1
Quando si parla di crittografia vanno distinti due termini: cifrario, ovvero la trasformazione carattere per carattere del messaggio, e codice, che rimpiazza ogni parola con un'altra parola (non più usati).

\subsubsection{Introduzione alla crittografia}
Un messaggio da cifrare è detto testo in chiaro e sono trasformati in testo cifrato da un funzione secondo una chiave di cifratura.
Decifrare è l'operazione legittima di lettura dei dati, traducendoli nel messaggio originale, mentre decriptare è l'attività di decifrazione da parte dell'intruso.

Secondo il principio di Kerckhoff, tutti gli algoritmi di cifratura devono essere pubblici e solo le chiavi sono segrete.
Infatti di solito cercare di tenere nascosto l'algoritmo non è produttivo, mentre averlo pubblico può portare a collaborazioni e miglioramenti.

Dato che la segretezza sta nella chiave, la sua lunghezza è la parte fondamentale.
Più è lunga, più è difficile da decriptare.

\subsubsection{Cifrari a sostituzione}
Il cifrario a sostituzione sostituisce una o più lettere con una o più lettere.
Uno dei cifrari più antichi è quello di Cesare, che effettuava uno slittamento dell'alfabeto di 3 lettere: A diventa D, B diventa E, ecc.
In generale, si può usare questo metodo usando una chiave k per spostare di k lettere l'alfabeto.
Questa cifratura è detta sostituzione monoalfabetica.

Il passaggio successivo è stato far cambiare la corrispondenza lettera in chiaro e lettera cifrata in maniera più casuale.
La chiave è la stringa che corrisponde all'intero alfabeto.

Anche se questo sistema sembra sicuro per il gran numero di combinazioni, 
più testo cifrato si ha a disposizione e più facile è decriptare il testo grazie alle proprietà statistiche dei linguaggi.
Basterà usare diagrammi o trigrammi più comuni (coppie o triple di lettere), o cercare di individuare una parola che è probabile che sia presente.

\subsubsection{Blocchi monouso}
[...]

\subsubsection{Due principi crittografici fondamentali}
I due principi crittografici fondamentali sono la ridondanza e l'attualità.
Il primo principio afferma che tutti i messaggi cifrati devono contenere una qualche forma di ridondanza, cioè un'informazione non necessaria al messaggio.
Questo per evitare che gli intrusi possano creare dati casuali con il rischio che vengano interpretati come validi.
La ridondanza però renderebbe più facile decriptare: quindi difende contro gli intrusi attivi, ma meno da quelli passivi. 

Il secondo principio afferma che è necessario avere la possibilità di verificare che ogni messaggio ricevuto sia attuale, recente, in modo da poter prevenire attacchi di tipo ripetizione, 
dove un intruso manda messaggi vecchi spacciandoli per nuovi.

\subsection{Algoritmi a chiave simmetrica} % 8.2
Questi algoritmi usano la stessa chiave per cifrare e decifrare.
Gli algoritmi possono essere implementati in software o hardware (es: P-box, scatola di permutazione con input a 8 bit).

\subsubsection{DES}

\subsubsection{AES}

\subsubsection{Modalità di cifratura}

\paragraph{Modalità ECB}

\paragraph{Modalità stream cipher}

\subsection{Algoritmi a chiave pubblica} % 8.3 - TUTTO

\subsection{Message digest} % 8.4.3 (partire da 8.4)

\subsubsection{MD5}

\subsubsection{SHA-1}

\subsection{Sicurezza delle comunicazioni} % 8.6

\subsubsection{IPsec} % 8.6.1

\subsubsection{Firewall} % 8.6.2

\subsubsection{Sicurezza wireless} % 8.6.4

\paragraph{802.11}

\paragraph{WAP 2.0}

\subsection{Replay attack} % 8.7.3 (conviene guardare da 8.7)

\subsection{Sicurezza del naming} % 8.9.2

\subsubsection{DNS spoofing}

\subsubsection{DNS sicuro}

